{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tqdm as notebook_tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet architecture\n",
    "\n",
    "We will try to first build our model based on the Unet architecture because from our personal research, this architecture seems to be commonly used for image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>objects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1517</td>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\princ\\.cache...</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'id': [20602, 20603, 20604, 20605, 20606], 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030</td>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\princ\\.cache...</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'id': [14034, 14035, 14036, 14037, 14038, 140...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217</td>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\princ\\.cache...</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>{'id': [16678, 16679, 16680, 16681, 16682, 166...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                              image  width  height  \\\n",
       "0      1517  {'bytes': None, 'path': 'C:\\Users\\princ\\.cache...    500     500   \n",
       "1      1030  {'bytes': None, 'path': 'C:\\Users\\princ\\.cache...    500     500   \n",
       "2      1217  {'bytes': None, 'path': 'C:\\Users\\princ\\.cache...    500     500   \n",
       "\n",
       "                                             objects  \n",
       "0  {'id': [20602, 20603, 20604, 20605, 20606], 'a...  \n",
       "1  {'id': [14034, 14035, 14036, 14037, 14038, 140...  \n",
       "2  {'id': [16678, 16679, 16680, 16681, 16682, 166...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "image_train_dataset = load_dataset(\n",
    "'keremberke/satellite-building-segmentation',\n",
    "split='train', name='mini'\n",
    ").to_pandas()\n",
    "image_train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes needed for the model definition\n",
    "\n",
    "class layer_conv2():\n",
    "    # Give as parameter the input and output channel\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(layer_conv2, self).__init__()\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=output_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=output_channel, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class begin_model():\n",
    "    # Give as parameter the input and output channel\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(begin_model, self).__init__()\n",
    "        self.first_step = layer_conv2(input_channel, output_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_step(x)\n",
    "        return x\n",
    "    \n",
    "class end_model():\n",
    "    # Give as parameter the input and output channel\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(end_model, self).__init__()\n",
    "        self.final_step = nn.Conv2d(in_channels=input_channel, out_channels=output_channel, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.final_step(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Classes necessary for 'creating' the U shape of the architecture\n",
    "    \n",
    "class down(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(down, self).__init__()\n",
    "        self.move_down = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            layer_conv2(input_channel, output_channel)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.move_down(x)\n",
    "        return x\n",
    "\n",
    "class up():\n",
    "\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super(up, self).__init__()\n",
    "        self.move_up = nn.Sequential(\n",
    "\n",
    "        )\n",
    "\n",
    "        self.move_up = layer_conv2(input_channel, output_channel)\n",
    "\n",
    "    def forward(x):\n",
    "\n",
    "        return x\n",
    "\n",
    "class complete_model():\n",
    "    # We give the number of classes expected and the number of channels\n",
    "    def __init__(self, num_chan, num_class):\n",
    "        super(complete_model, self).__init__()\n",
    "        self.debut = begin_model(num_chan, output_channel=64)\n",
    "        self.d1 = down(input_channel=64, output_channel=128)\n",
    "        self.d2 = down(input_channel=128, output_channel=256)\n",
    "        self.u1 = up(input_channel=256, output_channel=128)\n",
    "        self.u2 = up(input_channel=128, output_channel=64)\n",
    "        self.fin = end_model(input_channel=64, output_channel=num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.debut(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.u1(x)\n",
    "        x = self.u2(x)\n",
    "        x = self.fin(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
